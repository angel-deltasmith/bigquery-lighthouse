{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7ZAz2gNzrwZko7QiA2yyv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angel-deltasmith/bigquery-lighthouse/blob/main/Connection_to_lighthouse\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyjeHZoM-hWH"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade google-cloud-BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-BigQuery=\"/content/dbtkey.json\""
      ],
      "metadata": {
        "id": "uPAo_66f-vMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b21f058-6db6-4f12-f5f0-a2b08030283a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'google-cloud-BigQuery=/content/dbtkey.json'\n",
            "Hint: It looks like a path. File 'google-cloud-BigQuery=/content/dbtkey.json' does not exist.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export GOOGLE_APPLICATION_CREDENTIALS=\"/content/dbtkey.json\"\n"
      ],
      "metadata": {
        "id": "0PpkljVU_Ros"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade google-cloud-bigquery\n"
      ],
      "metadata": {
        "id": "ogQMmIRZ_YFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud"
      ],
      "metadata": {
        "id": "qOt6ziV8BB7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-bigquery"
      ],
      "metadata": {
        "id": "5PfArA7mBPT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-bigquery"
      ],
      "metadata": {
        "id": "5KFiIIsOBS6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud.bigquery.client import Client\n",
        "client = Client.from_service_account_json('/content/dbtkey.json', project='dbt-project-335000')"
      ],
      "metadata": {
        "id": "IsXQVXxyDKM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.list_datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skYWCHmxD5CI",
        "outputId": "237210b8-78d4-4bce-8b2f-2d2dcf4f9582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.api_core.page_iterator.HTTPIterator at 0x7f6b352355d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "project_id = 'dbt-project-335000'\n",
        "\n",
        "datasets = list(client.list_datasets())  # Make an API request.\n",
        "project = client.project\n",
        "\n",
        "if datasets:\n",
        "    print(\"Datasets in project {}:\".format(project))\n",
        "    for dataset in datasets:\n",
        "        print(\"\\t{}\".format(dataset.dataset_id))\n",
        "else:\n",
        "    print(\"{} project does not contain any datasets.\".format(project))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brsWzHcZA11S",
        "outputId": "88cf99d4-48d0-4015-9e3d-82dd04eecdb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets in project dbt-project-335000:\n",
            "\tdbt_mangel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tables = list(client.list_tables('dbt_mangel'))"
      ],
      "metadata": {
        "id": "oUQ8z3sEA17K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = client.query('''\n",
        "  SELECT \n",
        "    * \n",
        "  FROM `dbt-project-335000.dbt_mangel.input_test`''').result().to_dataframe()\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNT6w2aZI740",
        "outputId": "6096e75f-2700-4428-bd1e-3a812488e4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/google/cloud/bigquery/table.py:1563: UserWarning: Dependency google-cloud-bigquery-storage is outdated, please upgrade it to version >= 2.0.0 (version found: 0.0.0).\n",
            "  warnings.warn(str(exc))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                   name                               url\n",
            "0   1  Arctic Travel Company  https://arctictravelcompany.com/\n",
            "1   2           Fjell Heisen                www.fjellheisen.no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set table_id to the ID of the table model to fetch.\n",
        "output_table_id = 'dbt-project-335000.dbt_mangel.output_test'\n",
        "\n",
        "# Make an API request.\n",
        "table = client.get_table(output_table_id)  \n",
        "\n",
        "# View table properties\n",
        "print(f\"Got table {output_table_id}.\")\n",
        "print(f\"Table schema: {table.schema}\")\n",
        "print(f\"Table description: {table.description}\")\n",
        "print(f\"Table has {table.num_rows} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha3qu9DQPWZ-",
        "outputId": "5f1d159f-321e-4c16-b9f4-58bdd0006ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got table dbt-project-335000.dbt_mangel.output_test.\n",
            "Table schema: [SchemaField('fetch_time', 'TIMESTAMP', 'NULLABLE', 'Timestamp when the audit was performed.', (), None), SchemaField('site_url', 'STRING', 'NULLABLE', 'URL that was audited.', (), None), SchemaField('site_id', 'STRING', 'NULLABLE', 'Site ID and Pub/Sub trigger message.', (), None), SchemaField('user_agent', 'STRING', 'NULLABLE', 'User-Agent string of the browser that did the audit.', (), None), SchemaField('job_id', 'STRING', 'NULLABLE', 'The BigQuery Job ID of the load.', (), None), SchemaField('emulated_as', 'STRING', 'NULLABLE', 'The device type that was emulated for the audit.', (), None), SchemaField('accessibility', 'RECORD', 'REPEATED', 'These checks highlight opportunities to [improve the accessibility of your web app](https://developers.google.com/web/fundamentals/accessibility). Only a subset of accessibility issues can be automatically detected so manual testing is also encouraged.', (SchemaField('total_score', 'FLOAT', 'NULLABLE', 'Total score of this category.', (), None), SchemaField('bypass_repetitive_content', 'BOOLEAN', 'NULLABLE', 'Adding ways to bypass repetitive content lets keyboard users navigate the page more efficiently. [Learn more](https://dequeuniversity.com/rules/axe/2.2/bypass?application=lighthouse).', (), None), SchemaField('color_contrast', 'BOOLEAN', 'NULLABLE', 'Low-contrast text is difficult or impossible for many users to read. [Learn more](https://dequeuniversity.com/rules/axe/2.2/color-contrast?application=lighthouse).', (), None), SchemaField('document_title_found', 'BOOLEAN', 'NULLABLE', 'The title gives screen reader users an overview of the page, and search engine users rely on it heavily to determine if a page is relevant to their search. [Learn more](https://developers.google.com/web/tools/lighthouse/audits/title).', (), None), SchemaField('no_duplicate_id_attribute', 'BOOLEAN', 'NULLABLE', None, (), None), SchemaField('html_has_lang_attribute', 'BOOLEAN', 'NULLABLE', \"If a page doesn't specify a lang attribute, a screen reader assumes that the page is in the default language that the user chose when setting up the screen reader. If the page isn't actually in the default language, then the screen reader might not announce the page's text correctly. [Learn more](https://dequeuniversity.com/rules/axe/2.2/html-lang?application=lighthouse).\", (), None), SchemaField('html_lang_is_valid', 'BOOLEAN', 'NULLABLE', 'Specifying a valid [BCP 47 language](https://www.w3.org/International/questions/qa-choosing-language-tags#question) helps screen readers announce text properly. [Learn more](https://dequeuniversity.com/rules/axe/2.2/valid-lang?application=lighthouse).', (), None), SchemaField('images_have_alt_attribute', 'BOOLEAN', 'NULLABLE', 'Informative elements should aim for short, descriptive alternate text. Decorative elements can be ignored with an empty alt attribute. [Learn more](https://dequeuniversity.com/rules/axe/2.2/image-alt?application=lighthouse).', (), None), SchemaField('form_elements_have_labels', 'BOOLEAN', 'NULLABLE', 'Labels ensure that form controls are announced properly by assistive technologies, like screen readers. [Learn more](https://dequeuniversity.com/rules/axe/2.2/label?application=lighthouse).', (), None), SchemaField('links_have_names', 'BOOLEAN', 'NULLABLE', 'Link text (and alternate text for images, when used as links) that is discernible, unique, and focusable improves the navigation experience for screen reader users. [Learn more](https://dequeuniversity.com/rules/axe/2.2/link-name?application=lighthouse).', (), None), SchemaField('lists_are_well_formed', 'BOOLEAN', 'NULLABLE', 'Screen readers have a specific way of announcing lists. Ensuring proper list structure aids screen reader output. [Learn more](https://dequeuniversity.com/rules/axe/2.2/list?application=lighthouse).', (), None), SchemaField('list_items_within_proper_parents', 'BOOLEAN', 'NULLABLE', 'Screen readers require list items (`<li>`) to be contained within a parent `<ul>` or `<ol>` to be announced properly. [Learn more](https://dequeuniversity.com/rules/axe/2.2/listitem?application=lighthouse).', (), None), SchemaField('meta_viewport_allows_zoom', 'BOOLEAN', 'NULLABLE', 'Disabling zooming is problematic for users with low vision who rely on screen magnification to properly see the contents of a web page. [Learn more](https://dequeuniversity.com/rules/axe/2.2/meta-viewport?application=lighthouse).', (), None)), None), SchemaField('best_practices', 'RECORD', 'REPEATED', None, (SchemaField('total_score', 'FLOAT', 'NULLABLE', 'Total score of this category.', (), None),), None), SchemaField('performance', 'RECORD', 'REPEATED', None, (SchemaField('total_score', 'FLOAT', 'NULLABLE', 'Total score of this category.', (), None),), None), SchemaField('pwa', 'RECORD', 'REPEATED', None, (SchemaField('total_score', 'FLOAT', 'NULLABLE', 'Total score of this category.', (), None),), None)]\n",
            "Table description: None\n",
            "Table has 0 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table_id = 'dbt-project-335000.dbt_mangel.output2'\n",
        "table = client.get_table(table_id)  \n",
        "# View table properties\n",
        "print(f\"Got table {table_id}.\")\n",
        "print(f\"Table schema: {table.schema}\")\n",
        "print(f\"Table description: {table.description}\")\n",
        "print(f\"Table has {table.num_rows} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xktqYkDwQ8I1",
        "outputId": "bb09a09d-e974-4e4e-c024-ceb19cc97bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got table dbt-project-335000.dbt_mangel.output2.\n",
            "Table schema: [SchemaField('id', 'INTEGER', 'NULLABLE', None, (), None), SchemaField('name', 'STRING', 'NULLABLE', None, (), None), SchemaField('url', 'STRING', 'NULLABLE', None, (), None)]\n",
            "Table description: None\n",
            "Table has 6 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table_id_output = 'dbt-project-335000.dbt_mangel.output2'\n",
        "job_config = bigquery.QueryJobConfig(destination=table_id_output)#parameters = destination table to write \n",
        "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND #If the table already exists, then append the rows\n",
        "\n",
        "#Get the values from the input table\n",
        "sql = \"\"\"\n",
        "    SELECT \n",
        "    * \n",
        "  FROM `dbt-project-335000.dbt_mangel.input_test`;\n",
        "\"\"\"\n",
        "\n",
        "# Start the query, passing in the extra configuration.\n",
        "query_job = client.query(sql, job_config=job_config)  # Make an API request.\n",
        "query_job.result()  # Wait for the job to complete.\n",
        "\n",
        "\n",
        "print(\"Query results loaded to the table {}\".format(table_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJgKVR8zQEiu",
        "outputId": "cc7d2e01-280a-4519-b20a-eba6d2b076b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query results loaded to the table dbt-project-335000.dbt_mangel.output2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LIGHTHOUSE PYTHON\n",
        "!npm install -g lighthouse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFupV_40luJO",
        "outputId": "348c656b-7adc-47ba-91e9-5ee226d6e679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35mdeprecated\u001b[0m intl-messageformat-parser@1.8.1: We've written a new parser that's 6x faster and is backwards compatible. Please use @formatjs/icu-messageformat-parser\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35mdeprecated\u001b[0m uuid@3.3.2: Please upgrade  to version 7 or higher.  Older versions may use Math.random() in certain circumstances, which is known to be problematic.  See https://v8.dev/blog/math-random for details.\n",
            "\u001b[K\u001b[?25h/tools/node/bin/lighthouse -> /tools/node/lib/node_modules/lighthouse/lighthouse-cli/index.js\n",
            "/tools/node/bin/chrome-debug -> /tools/node/lib/node_modules/lighthouse/lighthouse-core/scripts/manual-chrome-launcher.js\n",
            "/tools/node/bin/smokehouse -> /tools/node/lib/node_modules/lighthouse/lighthouse-cli/test/smokehouse/frontends/smokehouse-bin.js\n",
            "\u001b[K\u001b[?25h+ lighthouse@9.2.0\n",
            "added 137 packages from 134 contributors in 12.02s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import modules \n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from numpy.lib.function_base import extract\n",
        "from datetime import datetime\n",
        "from os.path import join\n",
        "from openpyxl import Workbook\n"
      ],
      "metadata": {
        "id": "Vg-uNI-UvKF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install pipes\n",
        "!pip install openpyxl\n",
        "!pip install DateTime\n",
        "!pip install join\n",
        "!pip install export"
      ],
      "metadata": {
        "id": "XNfA1T4FmjPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create needed variables\n",
        "wb1 = Workbook()\n",
        "wb2 = Workbook()\n",
        "name = \"Report\"\n",
        "getdate = datetime.now().strftime(\"%m-%d-%y\")\n",
        "relative_path = '/content/Outputfiles'\n",
        "csv_file_mob = join(relative_path, 'lighthouse_mobile_' + getdate + '.csv')\n",
        "csv_file_des = join(relative_path, 'lighthouse_desktop_' + getdate + '.csv')\n",
        "\n",
        "#Detecte the active sheets\n",
        "ws_mob = wb1.active\n",
        "ws_des = wb2.active\n",
        "def last_row_mob(): return len(ws_mob['A'])\n",
        "def last_row_des(): return len(ws_des['A'])\n",
        "\n",
        "urls = [\n",
        "\"https://arctictravelcompany.com/\",\n",
        "\"http://www.fjellheisen.no\",\n",
        "]\n",
        "\n",
        "base = { 1: 'First Run', 2: 'Second Run', 3: 'Third Run', 4: 'Fourth Run', 5: 'Fifth Run', 6: 'Sixth Run'}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOBR8e3Mm9yd",
        "outputId": "b375d00e-9910-4dae-cb80-a90bc5dd1d8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-26 03:31:04.109451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Lighthouse\n",
        "def extract_info(run, preset):\n",
        "    header = [run, 'Product_Name', 'URL', 'First_Contentful_Paint', 'Speed_Index', 'Largest_Contentful_Paint', 'SEO', 'Performance', 'Best_Practices']\n",
        "    if preset == 'desktop':     ### preset -> 2 values: 'desktop' & 'perf'(for mobile)\n",
        "            last = last_row_des()+1\n",
        "            working = ws_des\n",
        "    else:\n",
        "        last = last_row_mob()+1\n",
        "        working = ws_mob\n",
        "\n",
        "    if 'first' not in run.lower():\n",
        "        last += 1\n",
        "\n",
        "    for i, r in enumerate('ABCDEFGHI'):\n",
        "        working[r+str(last)].value = header[i]\n",
        "    print('Validation completed')\n",
        "#Send URLs list\n",
        "    for url in urls:\n",
        "        stream = os.popen('lighthouse --chrome-flags=\"--headless\"--disable-storage-reset=\"true\" --preset=' +\n",
        "                          preset + ' --output=json --output-path='+relative_path + name+'_'+getdate+'.report.json ' + url)\n",
        "        print(relative_path + name+'_'+getdate+'.report.json ')\n",
        "        time.sleep(60)\n",
        "        json_filename = join(relative_path, name + '_' +\n",
        "                             getdate + '.report.json')\n",
        "        print(json_filename)\n",
        "        ### open the JSON FILE and start processing it\n",
        "\n",
        "        with open(json_filename, encoding=\"utf8\",mode =\"a+\") as json_data:\n",
        "            loaded_json = json.load(json_data)\n",
        "            print(loaded_json)\n",
        "\n",
        "            \n",
        "\n",
        "        #Set the values we need \n",
        "               ### set the items you need from the JSON FILE here\n",
        "        try: \n",
        "            product_name = loaded_json[\"audits\"][\"largest-contentful-paint-element\"][\"details\"][\"items\"][0][\"node\"][\"nodeLabel\"] ### get the name of the product to be descriptive\n",
        "            fcps = str(round(loaded_json[\"audits\"][\"first-contentful-paint\"][\"score\"] * 100))\n",
        "            sis = str(round(loaded_json[\"audits\"][\"speed-index\"][\"score\"] * 100))\n",
        "            lcps = str(round(loaded_json[\"audits\"][\"largest-contentful-paint\"][\"score\"] * 100))\n",
        "            seo = str(round(loaded_json[\"categories\"][\"seo\"][\"score\"] * 100))\n",
        "            performance = str(round(loaded_json[\"categories\"][\"performance\"][\"score\"] * 100))\n",
        "            best_practices = str(round(loaded_json[\"categories\"][\"best-practices\"][\"score\"] * 100))\n",
        "        except Exception as e:\n",
        "            product_name = fcps = sis = lcps = seo = performance = best_practices = '-'\n",
        "            print(e)\n",
        "\n",
        "        ### (1) if you want to add a new column for the report you need to create a new var as fcps, fcpdv for eg. (see below) -- these are coming from JSON FILE\n",
        "        ### (2) go to the line, where the 'header' AKA dataFrame is initialised (above all - even under the declaration of the function) and add the new item as a string for eg: [..., 'lcpdv']\n",
        "        ### (3) go to the line where the enumeration was set and add another letter which corresponds with the next column in excel [...,JKLMN...]\n",
        "        ### (4) go to the line where we set the 'header' for the excel report -> data: [urls.index(url),...., lcpdv]\n",
        "        ### (5) go to the line where the enumeration was set and add another letter which corresponds with the next column in excel [...,JKLMN...]\n",
        "  \n",
        "  ### if you increase the columns for your report, don't forget to add them below -> data = [..., sidv] !!! steps -> (4) - (5)\n",
        "    data = [urls.index(url), product_name, url, fcps, sis, lcps, seo, performance, best_practices]\n",
        "    if preset == 'desktop':\n",
        "        last = last_row_des()+1\n",
        "    else:\n",
        "        last = last_row_mob()+1\n",
        "    for i, r in enumerate('ABCDEFGHI'):\n",
        "        working[r+str(last)].value = data[i]\n",
        "\n",
        "### here you can set how many times to run the test on the links\n",
        "\n",
        "num_of_call = 1\n",
        "for i in range(1, num_of_call+1):\n",
        "    extract_info(base[i], preset='perf') ### run the test on mobile\n",
        "    extract_info(base[i], preset='desktop') ### run the test on desktop\n",
        "\n",
        "wb1.save(csv_file_mob)  ### save the results for mobile in an EXCEL FILE\n",
        "wb2.save(csv_file_des) ### save the results for desktop in an EXCEL FILE\n",
        "        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "3VMSMx9SpAb7",
        "outputId": "59e0eb5c-2c98-48e5-a277-0afa509efcb4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation completed\n",
            "/content/OutputfilesReport_12-26-21.report.json \n",
            "/content/Outputfiles/Report_12-26-21.report.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-7a60cd477bc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mnum_of_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_call\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mextract_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'perf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### run the test on mobile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mextract_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'desktop'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### run the test on desktop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-7a60cd477bc4>\u001b[0m in \u001b[0;36mextract_info\u001b[0;34m(run, preset)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"a+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mloaded_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección nueva"
      ],
      "metadata": {
        "id": "hjGUUDix1tea"
      }
    }
  ]
}